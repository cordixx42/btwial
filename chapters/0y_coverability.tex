\chapter{The Backwards Reachability Algorithm}\label{chapter:coverability}

The main purpose of the thesis is to use weakly acyclic languages to address the coverability problem in Petri nets. Therefore, the data structure of the Table of Nodes from \autoref{chapter:datastructure} and the operations it provides are used in order to realize the Backwards Reachability Algorithm for solving the coverability problem. This chapter begins with refreshing the coverability problem and describing a general form of the Backwards Reachability Algorithm, before adapting it to integrate the  Table of Nodes.

\section{Abstract Backwards Reachability Algorithm}\label{sec:abstractbw} 
Given a Petri Net $N$ with start marking $M_{0}$, we say that a marking $M$ is coverable in $(N,M_{0})$, if there exists a reachable marking $M'$, where $M'\ge M$. 
%We say $M'$ covers $M$ for $M'\ge M$, which means for each place in the Petri net, marking $M'$ has at least the number of tokens as in $M$.

The coverability problem, decides for a Petri Net, a start marking $M_{0}$ and a target marking $M$, if there is a sequence of transitions leading to a marking $M'$, which covers $M$. It has been shown, that the coverability problem is EXPSPACE-complete. 
\todo{complexity of problem, space hierarchy theorem, cite rackoff lipton}

\par
There are various procedures aiming to solve the difficult problem of coverability. For instance, Rackoff's algorithm uses the construction of the reachability graph until a certain depth for . 
\par
The method, which is used in this thesis is the Backwards Reachability Algorithm. This method iteratively calculates the set of all predecessor markings, which can cover $M$ and verifies, if $M_{0}$ is part of the set. Formally, we define this set as the following.
\begin{definition}\label{def:ppre}
$\ppre_{N}(\mathcal{M}) = \bigcup_{t \in \Tr} \{M': M' \xrightarrow{t} M \ , \ M \in \mathcal{M} \}$ is the \emph{Predecessor set} and contains the set of all markings $M'$, which evolve into a marking in $\mathcal{M}$ by firing one transition $t$ of the Petri net $N = (S,\Tr,F)$.
\end{definition}
\par 
The abstract procedure of the Backwards Reachability Algorithm is presented in \autoref{alg:bw}. The input are the Petri net $N$, the start configuration $M_{0}$ and the target configuration $M$. In line 1, we initialize the set $\mathcal{M}$ with the upward closed set with $M$ as the sole minimal element. $\mathcal{M}$ contains all markings $M'$, which cover $M$. Another set $\mathcal{M}_{\text{old}}$ has the purpose of storing the state of $\mathcal{M}$ from the last iteration and is initially set to the empty set in line 2.

\begin{algorithm}[htb]
\caption{Backwards Reachability Algorithm}\label{alg:bw}
\begin{algorithmic}[1]
\Input {$N, M_{0}, M$}
\State $\mathcal{M} \gets \{ M^{'} : M^{'} \ge M \}$
\State $\mathcal{M}_{\text{old}} \gets \emptyset$
\While{true}
	\State $\mathcal{M}_{\text{old}} \gets \mathcal{M}$
	\State $\mathcal{M}_{\text{pre}} \gets \ppre_{N}(\mathcal{M})$
	\State $\mathcal{M} \gets \mathcal{M}  \cup \mathcal{M}_{\text{pre}}$
\If{$M_{0} \in \mathcal{M}$}
	\Return true
\EndIf
\If{$\mathcal{M} = \mathcal{M}_{\text{old}}$}
    \Return false
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

The rest of the procedure happens in the while loop from line 3 onwards. In each iteration, the predecessors $\ppre_{N}(\mathcal{M})$ of all configurations in $\mathcal{M}$ are computed in line 5 and inserted into $\mathcal{M}$ in line 6. 
%Here, the $pre(\mathcal{M})$ returns the set of all predecessors of the markings in $\mathcal{M}$ by executing one transition $t \in T$ of the Petri net. 
%Here, the set $\ppre(\mathcal{M})$ from Definition~\autoref{def:ppre} is used
%Here, the set $\ppre(\mathcal{M}) = \cup_{t \in T} \{M': M' \xrightarrow{t} M, M \in \mathcal{M} \}$ contains all markings $M'$, which develop into a marking in $\mathcal{M}$ by executing one transition $t$ of the net.
\par
In line 7 we check, if the start marking $M_{0}$ has been added to this accumulating set of predecessors. If it is contained in $\mathcal{M}$, there exists a series of transitions transforming $M_{0}$ into a marking, which covers $M$. This indicates $M$ is coverable in $(N,M_{0})$ and we return true. 
%Next we examine in line 8, if the $\ppre$ has has added any new elements into $\mathcal{M}$. 
\par
At the start of each iteration in line 4 $\mathcal{M}_{\text{old}}$ is set to $\mathcal{M}$, before $\mathcal{M}$ is extended with the predecessors. Therefore, the comparison of $\mathcal{M}$ and $\mathcal{M}_{0}$ in line 9 is confirming, if any new elements have been added into $\mathcal{M}$ in line 5. If $\mathcal{M}$ has not changed in this iteration, it also will not change in any future one, which indicates $M$ is not coverable and we return false.
\par
As the abstract \autoref{alg:bw} operates on infinite sets of markings, it is not directly implementable in this form. 

\begin{lemma}\label{lem:upwclosed}
During the execution of \autoref{alg:bw} the set $\mathcal{M}$ remains upward closed. 
\end{lemma}
\begin{proof}
Upwards closed sets are closed under union and $\ppre$. 
\end{proof}


\begin{lemma}\label{lem:bwterm}
\autoref{alg:bw} terminates. 
\end{lemma}
\begin{proof}
Define $\ppre_{N}(\mathcal{M})$ as the 
\end{proof}

As described in the chapter on the preliminaries, each upward closed set can be described by a finite number of minimal elements. Furthermore, Lemma~\autoref{lem:upwclosed} shows that the sets used in the algorithm always stay upwards closed. Existing implementations use these properties and express $\mathcal{M}$ with its finite set of minimal markings during the whole procedure.

\todo{minimal markings exponential number, why automata might be better}


%\begin{lemma}\label{lem:uppre}
%If $\mathcal{M}$ is upward closed, then $\ppre(\mathcal{M})$ is also upward closed.
%\end{lemma}

\section{Using the Table of Nodes for the Backwards Reachability}
\todo{why we can assume for pre that it will stay weakly acyclic: upwards closed markings: lemma and new figure}
%For our approach we want to describe the infinite upward closed sets in the Backwards Reachability Algorithm with finite representations of automata. We use the nodes in the table, which characterize weakly acyclic languages, to encode markings and upward closed set of markings. 
The \autoref{alg:bw} is working with infinite upward-closed sets of markings, like $\mathcal{M}$ and $\mathcal{M}_{\text{old}}$. Since automata are characterizing languages, which are a set of words, they are a way to describe these infinite sets in a compact finite representation. For our approach, we want to implement the Backwards Reachability Algorithm with the Table of Nodes data structure from \autoref{chapter:datastructure} by modelling the markings of Petri nets with weakly acyclic languages. 

\par 

\autoref{fig:markingtonode} shows the mapping between the infinite sets and the nodes in the table. 
\par 

In the upper row of the figure, the procedure from \autoref{alg:bw} with infinite sets of markings is shown. 
$\mathcal{M}_{i}$ denotes the upward closed set $\mathcal{M}$ in iteration $i$ of the loop starting in line 3 of \autoref{alg:bw} and iteration $n$ is the last iteration, where the procedure terminates. With the calculation of the Predecessor set $\ppre$ and set union $\cup$, we transition from the set $\mathcal{M}_{i}$  to $\mathcal{M}_{i+1}$.

\par 

The lower row shows the implementation of the Backwards Reachability Algorithm making use of the Table of Nodes. We map the infinite sets $\mathcal{M}_{i}$ to nodes $q_{i}$ in the table using a specific encoding scheme. The operations $\ppre$ and $\cup$ are performed with equivalent table operations $\pre$ and $\union$, which were examined in \autoref{chapter:datastructure}.
Given the node $q_{i}$, which is encoding $\mathcal{M}_{i}$, performing one iteration in the lower row yields the node $q_{i+1}$, which is exactly the encoding for $\mathcal{M}_{i+1}$.

\todo{describe with diagram the relationship between markings and nodes}

\begin{figure}[htb]
\centering
\caption{Relationship between the markings and nodes}\label{fig:markingtonode}
\begin{tikzcd}[scale cd = 1.3, row sep=huge]
%[sep=large,every arrow/.append style={maps to}, every label/.append style={font=\normalsize}]
\mathcal{M}_{1} \arrow[r,"\ppre \ + \ \cup"] \arrow[d, leftrightarrow,""{name=D1}] &[6em]
  \mathcal{M}_{2} \arrow[r,"\ppre \ + \ \cup"] \arrow[d, leftrightarrow,""{name=D2}] &[6em]
  \mathcal{M}_{3} \arrow[r, dashed] \arrow[d, leftrightarrow,""{name=D3}] &[6em]
  \mathcal{M}_{n} \arrow[d, leftrightarrow,""{name=D3}] &[10em] \\
  q_{1} \arrow[r,"T.\pre \ + \ T.\union"] &
  q_{2} \arrow[r,"T.\pre \ + \ T.\union"] &
  q_{3} \arrow[r, dashed] &
  q_{n}
\end{tikzcd}
\end{figure}

\par

\autoref{alg:bw_wwa} shows the adjusted Backward Reachability Algorithm. On the left side the implementation with the Table of Nodes is sketched. On the right, the corresponding lines of \autoref{alg:bw} are depicted in gray.

\par 

Analogous to \autoref{alg:bw}, the input are a Petri net, start configuration and end configuration. In line 1 the Table of Nodes $\tbl$ is initialized with an empty table containing only $q_{\emptyset}$, $q_{\Sigma^{*}}$ and $q_{\epsilon}$. 

%\begin{algorithm}[htb]
%\caption{Backwards Reachability Algorithm with Table of Nodes}\label{alg:bw_wwa}
%\begin{algorithmic}[1]
%\Input {$N, M_{0}, M$}
%\State $T \gets EmptyTableOfNodes$
%\State $\mathcal{T} \gets \textsf{net2transducer}(N)$
%\State $\mathcal{M}_{0} \gets T.\textsf{encode}(M_{0})$
%\State $\mathcal{M} \gets T.\textsf{encodeUpwardClosed}(M)$
%\State $\mathcal{M}_{\text{old}} \gets q_{\emptyset}$
%\While{true}
%	\State $\mathcal{M}_{\text{old}}  \gets \mathcal{M}$
%	\State $\mathcal{M}_{\text{pre}} \gets T.\pre(\{q_{0\mathcal{T}},\mathcal{M}\},\mathcal{T})$
%	\State $\mathcal{M} \gets T.\union(\mathcal{M}, \mathcal{M}_{\text{pre}})$
%\If{$T.\textsf{intersection}(\mathcal{M}_{0}, \mathcal{M}) \neq q_{\emptyset}$}
%	\Return true
%\EndIf
%\If{$\mathcal{M} = \mathcal{M}_{\text{old}} $}
%    \Return false
%\EndIf
%\EndWhile
%\end{algorithmic}
%\end{algorithm}

\newenvironment{algocolor}{%
   \color{gray}
}{}

\begin{algorithm}[htb]
\caption{Backwards Reachability Algorithm with Table of Nodes}\label{alg:bw_wwa}
\begin{minipage}[t]{0.6\textwidth}
\begin{algorithmic}[1]
\Input {$N, M_{0}, M$}
\State $\tbl \gets \text{EmptyTableOfNodes}$
\State $\mathcal{T} \gets \textsf{net2transducer}(N)$
\State $q_{0} \gets  \tbl.\textsf{encode}(M_{0})$
\State $q \gets \tbl.\textsf{encodeUpwardClosed}(M)$
\State $q_{\text{old}} \gets q_{\emptyset}$
\While{true}
	\State $q_{\text{old}}  \gets q$
	\State $q_{\text{pre}} \gets \tbl.\pre(\{q_{0\mathcal{T}},q\},\mathcal{T})$
	\State $q \gets \tbl.\union(q, q_{\text{pre}})$
\If{$\tbl.\inter(q_{0}, q) \neq q_{\emptyset}$}
	\Return true
\EndIf
\If{$q = q_{\text{old}} $}
    \Return false
\EndIf
\EndWhile
\end{algorithmic}
\end{minipage}
\begin{algocolor}
\begin{minipage}[t]{0.37\textwidth}
\begin{algorithmic}
\Input {$N, M_{0}, M$}
\State 
\State 
\State 
\State $\mathcal{M} \gets \{ M^{'} : M^{'} \ge M \}$
\State $\mathcal{M}_{\text{old}} \gets \emptyset$
\While{true}
	\State $\mathcal{M}_{\text{old}} \gets \mathcal{M}$
	\State $\mathcal{M}_{\text{pre}} \gets \ppre_{N}(\mathcal{M})$
	\State $\mathcal{M} \gets \mathcal{M}  \cup \mathcal{M}_{\text{pre}}$
\If{$M_{0} \in \mathcal{M}$}
	\Return true
\EndIf
\If{$\mathcal{M} = \mathcal{M}_{\text{old}}$}
    \Return false
\EndIf
\EndWhile
\end{algorithmic}
\end{minipage}
\end{algocolor}
\end{algorithm}

First, the input markings need to be transformed into their particular representation of a node in the table, which is the encoding shown by the bidirectional arrows between $\mathcal{M}_{i}$ and $q_{i}$ in \autoref{fig:markingtonode}. 
For this, we introduce new operations $\encode$ and $\encodeUp$. $\encode$ converts one marking to a node in the table, while $\encodeUp$ converts an upward closed set with one minimal marking into a node. The latter is used in line 4 and corresponds to the initialization of $\mathcal{M}$ before the loop on the right side.

%$\mathcal{M}_{\text{old}}$ is set to the node representing $\emptyset$ corresponding to line 2 of \autoref{alg:bw}. 
\par

The rest of the adapted operation remains very close to \autoref{alg:bw}. Each gray line on the right from the previous algorithm can be exactly mapped to a line of the adapted operation with the table on the left. The sets $\mathcal{M}, \mathcal{M}_{\text{old}}, \mathcal{M}_{\text{pre}}$ are encoded by the nodes $q,q_{\text{old}},q_{\text{pre}}$. The start marking $M_{0}$ corresponds to $q_{0}$. 
As already presented with \autoref{fig:markingtonode}, the $\ppre$ is replaced by $\pre$ and $\cup$ by $\union$. A slight difference between the algorithms is present in line 10. In the previous algorithm on the right we calculate if the start marking exists in the set $\mathcal{M}$. 
\todo{write reason of intersection here or only foreshadow?}
%The set union $\cup$ from line 5 in \autoref{alg:bw} is performed with the already introduced $\union$ operation of the table in line 9 of \autoref{alg:bw_wwa}. Furthermore, we use the $\inter$ operation of the table in line 10 to verify, if the start marking is contained in the predecessor set, corresponding to line 6 of the previous algorithm. The equality check of sets in line 8 of the abstract version can be transferred directly into an equality check of node ids in line 12 of the adapted version.

\par 

The only question remaining is the connection between the table operation $\pre$ described in \autoref{chapter:datastructure} and the $\ppre$ set from \autoref{alg:bw}. In fact, we construct the transducer $\mathcal{T}$ from the transitions of a Petri net in line 2 in a way, which makes both of these operations equivalent by expressing the same set of predecessor markings.

\par 

The next two subsections describe the encoding we chose for the markings and the corresponding construction of the transducer based on this encoding. 

\subsection{A Weakly Acyclic Encoding for Markings in Petri nets}
Recall, that a marking $M$ is defined as mapping from states in $S$ to a natural number, which shows how many tokens are assigned to a state by the marking. 
We define a fixed order on the places $S = (s_{1},s_{2},\dots,s_{n})$ of the Petri net $N$. Then a marking can be represented by a $n$-dimensional tuple $M = (m_{1},m_{2},\dots,m_{n})$, where $m_{i}$ is the number of tokens in place $s_{i}$ in that marking.

\par 

We define the following encoding for these markings.

\begin{definition}\label{def:encoding}
For a marking $M = (m_{1},m_{2},\dots,m_{n})$ we define its \emph{encoding} $f(M)$ as the language $L(\bm{1}^{m_{1}} \square \bm{1}^{m_{2}} \square \ldots \bm{1}^{m_{n}} \square)$ over $\Sigma = \{\bm{1}, \square\}$.
\end{definition}

%We look for an encoding for those marking vectors. Using the approach of an unary encoding for natural numbers, we limit the alphabet to $\Sigma = \{\bm{1}, \square\}$. 

As Definition~\autoref{def:encoding} illustrates, the token numbers in $M$ are encoded unary with $\bm{1}$s and the different positions in $M$ are separated with a separator symbol $\square$. For instance, the marking $m = (2,3,1)$ for a Petri net with 3 states is encoded into the language $L(\bm{11 \square 111 \square 1 \square})$. 
\todo{one marking is language of a single world}
\par 
With this straight-forward representation we can construct new table operations $\encode$ and $\encodeUp$, which have been applied in the Backwards Reachability Algorithm with the table \autoref{alg:bw_wwa}. 
% maybe put this only into encode section 
%Both functions build string $s$ into a regular expression for the language of the marking based on our encoding, and then passes the string to $\create$. The table operation $\create$, which has been presented in \autoref{chapter:datastructure}, creates the node and all its successors into the table before returning its identifier.
\par
The $\encode$ function is sketched in \autoref{alg:encode} and returns the node identifier of the language for the input marking $m$. In the adapted Backwards Reachability algorithm it computes the node for the start marking $M_{0}$ in line 3. The function builds string $s$ into a regular expression for the language of the marking based on our encoding $f$, and then passes the string to $\create$. The table operation $\create$, which has been presented in \autoref{chapter:datastructure}, creates the node and all its successors into the table before returning its identifier.

\par
There are two nested loops, where the outer one iterates over all elements of $M$. Inside the inner loop, we iteratively append $\bm{1}$ to the string $s$ until the amount $m_{i}$. After all the $\bm{1}$ have been added for the current place $i$ of the net, we insert the separator $\square$ in line 5.
Finally, we pass the complete string to the $\create$ method. 

\begin{figure}
\begin{minipage}[t]{0.46\textwidth}
\begin{algorithm}[H]
\caption{Encode a marking into a node}\label{alg:encode}
\begin{algorithmic}[1]
\Input {$M = (m_{1},m_{2},\dots,m_{n})$}
\State $s \gets \text{empty string}$
\ForEach {$m_{i} \in M$}
\ForEach {$k \in \{1,\dots,m_{i}\}$}
\State $s \gets s.\app(\bm{1})$
\EndFor
\State $s \gets s.\app(\bm{\square})$
\EndFor
\Return $\create (s)$
\end{algorithmic}
\end{algorithm}
\end{minipage}
\hfill
\begin{minipage}[t]{0.46\textwidth}
\begin{algorithm}[H]
\caption{Encode an upward set of marking into a node}\label{alg:encodeUp}
\begin{algorithmic}[1]
\Input {$M = (m_{1},m_{2},\dots,m_{n})$}
\State $s \gets \text{empty string}$
\ForEach {$m_{i} \in M$}
\ForEach {$k \in \{1,\dots,m_{i}\}$}
\State $s \gets s.\app(\bm{1})$
\EndFor
\State $s \gets s.\app(\bm{1*})$
\State $s \gets s.\app(\bm{\square})$
\EndFor
\Return $\create (s)$
\end{algorithmic}
\end{algorithm}
\end{minipage}
\end{figure}

The $\encodeUp$ operation also takes a marking $M$ as input. Instead of creating the language of the marking, $\encodeUp$ creates the language for the upward closed set with $M$ as the only minimal marking. In the Backwards Reachability Algorithm it is used to create the upward closed set for the end configuration  in line 4 of \autoref{alg:bw_wwa}.
\par
For the marking $M=(m_{1},m_{2},\dots,m_{n})$, $\encodeUp$ returns the language for the set $\{M': m'_{i} \ge m_{i} \ \forall i\}$. Based on the encoding in Definition~\autoref{def:encoding}, this is described by the language $L(\bm{1}^{m_{1}}\bm{1^{*}} \square \bm{1}^{m_{2}}\bm{1^{*}} \square \ldots \bm{1}^{m_{n}}\bm{1^{*}} \square)$. 
\todo{lemma out of this ?}
By adding $\bm{1^{*}}$ after every $\bm{1}^{m_{i}}$, we allow for each position in $M$ to have at least $m_{i}$ tokens.

\par
Using this, a slight modification of \autoref{alg:encode} leads to \autoref{alg:encodeUp} for the table operation $\encodeUp$. We only need to append the string $\bm{1*}$ after the inner for loop in line 5 of \autoref{alg:encodeUp} and the rest of the operation stays unchanged. 

\subsection{Representing a Petri Net with a Transducer}
After having fixed the encoding scheme in Definition~\autoref{def:encoding} last section, we now want to develop a consistent construction  of the transducer $\mathcal{T}$, which corresponds to the operation $\nettrans$ in line 2 of \autoref{alg:bw_wwa}. 
The transducer must be designed in a way, such that the $\pre$ of the table yields the same set of predecessor markings like $\ppre_{N}(\mathcal{M})$  we have defined in \autoref{sec:abstractbw}.

\par

Recall the Pre language and the Predecessor set we have defined. Here for the Pre language we define the input $L$ to directly express a language.
\begin{equation*}
\Pre_{\mathcal{T}}(L) = \{ w \in \Sigma^{*}: (w,v) \in L(\mathcal{T}), v \in L \} 
\end{equation*}
\begin{equation*}
\ppre_{N}(\mathcal{M}) = \bigcup_{t \in \Tr} \{M': M' \xrightarrow{t} M, M \in \mathcal{M} \}
\end{equation*}

We aim to design $\mathcal{T}$, such that the words $w$ in $\Pre_{\mathcal{T}}(L)$ are encoding the predecessor markings $M'$ in $\ppre_{N}(\mathcal{M})$
Formally, we want that the following equality holds:
\begin{equation*}
f(\ppre_{N}(\mathcal{M})) = \Pre_{\mathcal{T}}(f(\mathcal{M}))
\end{equation*}


%First, we replace the argument to be a node $q$ in the table for both sets. Furthermore, the single markings $M$ and $M'$ can be expressed as words $w,v \in \Sigma$. 

%\begin{equation*}
%\text{Pre}_{\mathcal{T}}(q) = \{ w \in \Sigma^{*}: (w,v) \in L(\mathcal{T}), v \in L(q) \} \\
%\end{equation*}
%\begin{equation*}
%\ppre(q) = \bigcup_{t \in T} \{w: w \xrightarrow{t} v, v \in L(q) \}
%\end{equation*}

%We aim to design $\mathcal{T}$, such that both of the sets are equivalent. We can already see, that for both sets to be equivalent, $(w,v)$ has to be accepted by the transducer $\mathcal{T}$ if and only if there is a transition $t$ such that the marking represented by $w$ becomes the marking represented by $v$ when firing $t$.
Therefore, the transducer must encode all transitions of the Petri net and relates a marking with one possible successor marking.


\subsubsection{Encoding of one Petri net transition}
A Petri net has a set of transitions $T$, which are connected to the states $S$ with the flow relation $F$. 
\todo{describe $F$ more}
With the fixed order of $S = (s_{1},s_{2},\dots,s_{n})$, we can describe the effect/change in the states induced by firing a single transition $t$ with a pair of $n$-dimensional vectors $t = (f,g)$. In $f$, the element on position $i$ $f_{i}$ indicates, how many tokens from $s_{i}$ are necessary to enable $t$. In $g$, the $i$-th element $g_{i}$ expresses, how many tokens flow into state $s_{i}$ after the firing of $t$. Therefore, the complete Petri net $N$ can be described by a set of $t = (f,g)$. 


\par 

Imagine a Petri net with a single transition $t=(f,g)$ with $f = (1,0,1)$ and $g = (1,3,1)$ in figure.

\begin{figure}[htb]
\centering 
\caption{Petri net example}\label{fig:pnet}
\begin{tikzpicture}
% Place 1
\node[place,
    fill=red!25,
    draw=red!75,
    tokens=0,
    label=$s_1$] (s1) at (0,2) {};
 
% Place 2
\node[place,
    fill=teal!25,
    draw=teal!75,
    tokens=0,
    label=$s_2$] (s2) at (4,2) {};
 
% Place 3
\node[place,
    fill=blue!25,
    draw=blue!75,
    tokens=0,
    label=below:$s_3$] (s3) at (2,0) {};
    
% Transition
%\node[transition,
%    label=$T$] (trans) at (2,2) {};


%\node[place,tokens=2,label=above:$p_1$]        (p1) {};
%  \node[place,label=above:$p_2\ge1$,right=of p1] (p2) {};
%
%  \node[transition,below right=of p1,label=below:$t_1$] {}
%    edge[pre]                 (p1)
%    edge[post] node[auto] {2} (p2);


%\node[transition, label=$t_1$] (trans) at (2,2) {}
%    edge[pre]                 (s1);
%    edge[pre]                 (s2);
%    edge[post] node[auto] {2} (s2);
%    edge[post] node[auto] {2} (s3);

\node[transition, label=$t_1$] at (2,2) {}  
edge [pre and post] (s2)
edge [pre and post] (s1)
%edge [pre]  node[auto] {1} (s1)
%edge [post] node[auto] {2} (s1)
edge [post] node[auto] {3} (s3);

%                                     edge [pre and post] (s3); 
\end{tikzpicture}
\end{figure}


Consider the marking $m=(1,2,3)$ depicted in figure. Based on the encoding, the node for this marking is the language of the word $w = 1 \square 11 \square 111 \square$. With this configuration transition $t_{1}$ is enabled and after firing we transition into $m'=(1,5,3)$ in figure. This marking is encoded by the word $v = 1 \square 11111 \square 111 \square$. 


\begin{minipage}{0.46\textwidth}
\begin{figure}[H]
\centering 
\caption{Petri net before executing $t_{1}$}\label{fig:mark}
\begin{tikzpicture}
% Place 1
\node[place,
    fill=red!25,
    draw=red!75,
    tokens=1,
    label=$s_1$] (s1) at (0,2) {};
 
% Place 2
\node[place,
    fill=teal!25,
    draw=teal!75,
    tokens=2,
    label=$s_2$] (s2) at (4,2) {};
 
% Place 3
\node[place,
    fill=blue!25,
    draw=blue!75,
    tokens=3,
    label=below:$s_3$] (s3) at (2,0) {};

\node[transition, label=$t_1$] at (2,2) {}  
edge [pre and post] (s2)
edge [pre and post] (s1)
edge [post] node[auto] {3} (s3);
\end{tikzpicture}
\end{figure}
\end{minipage}
\hfill
\begin{minipage}{0.46\textwidth}
\begin{figure}[H]
\centering 
\caption{Petri net after executing $t_{1}$}\label{fig:markprime}
\begin{tikzpicture}
% Place 1
\node[place,
    fill=red!25,
    draw=red!75,
    tokens=1,
    label=$s_1$] (s1) at (0,2) {};
 
% Place 2
\node[place,
    fill=teal!25,
    draw=teal!75,
    tokens=5,
    label=$s_2$] (s2) at (4,2) {};
 
% Place 3
\node[place,
    fill=blue!25,
    draw=blue!75,
    tokens=3,
    label=below:$s_3$] (s3) at (2,0) {};

\node[transition, label=$t_1$] at (2,2) {}  
edge [pre and post] (s2)
edge [pre and post] (s1)
edge [post] node[auto] {3} (s3);
\end{tikzpicture}
\end{figure}
\end{minipage}


\subsubsection{union of transducer or union of pre}
At this point, we already need to make an important design decision. There are two approaches for transducer.

\par

The first idea is to use one transducer for encoding all transitions of the Petri net. Then, we only need to perform the $\ppre$ once per iteration analogous in \autoref{alg:bw_wwa}. However, this makes the $\nettrans$ operation in line 2 more complicated, as we need to consider non-determinism and possibly multiple start states for the transducer. By incorporating all transitions into $\mathcal{T}$, there can exist multiple mappings for a word $w$: $(w,v) \in L(\mathcal{T})$ and $(w,v') \in L(\mathcal{T})$. 
%The table $\pre$ operation from \autoref{chapter:datastructure} also needs to be modified to deal with the multiple 

\par

The other option is to construct one single transducer for each transition. We perform $\pre$ for each transducer transition separately and union the result with the predecessor accumulation node $q$. This will result in the change highlighted in \autoref{alg:bw_wwa_final}. First, instead of one transducer we build a list of transducers $\mathcal{T}^{*}$, one for each transition in $N$, in line 2. Furthermore, we add a loop over all transducers in the list and move the $\pre$ and $\union$ computation into this inner loop.

\par

We decided to apply the second alternative for the implementation. 



\begin{algorithm}[htb]
\caption{Backwards Reachability Algorithm with Table of Nodes}\label{alg:bw_wwa_final}
\begin{algorithmic}[1]
\Input {$N, M_{0}, M$}
\State $T \gets \text{EmptyTableOfNodes}$
\State $\mathcal{T}^{*} \gets \textsf{net2transducers}(N)$
\State $\mathcal{M}_{0} \gets T.\textsf{encode}(M_{0})$
\State $\mathcal{M} \gets T.\textsf{encodeUpwardClosed}(M)$
\State $\mathcal{M}_{\text{old}} \gets q_{\emptyset}$
\While{true}
	\State $\mathcal{M}_{\text{old}}  \gets \mathcal{M}$
	\ForEach{$\mathcal{T} \in \mathcal{T}^{*}$}
	\State $\mathcal{M}_{pre} \gets T.\pre(\{q_{0\mathcal{T}},\mathcal{M}\},\mathcal{T})$
	\State $\mathcal{M} \gets T.\union(\mathcal{M}, \mathcal{M}_{pre})$
	\EndFor
\If{$T.\textsf{intersection}(\mathcal{M}_{0}, \mathcal{M}) \neq q_{\emptyset}$}
	\Return true
\EndIf
\If{$\mathcal{M} = \mathcal{M}_{\text{old}} $}
    \Return false
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}


Problem: $(w,v) \in L(\mathcal{T})$, but $w,v$ can have different lengths. By definition of transducer it only maps a word to another word of same length. Therefore, introduce padding symbol $x$. 



\subsubsection{Petri net transitions}
A Petri net has a set of transitions $T$, which are connected to the states $S$ with the flow relation $F$. $F$ maps




%Let the word $w$ encode the marking $M_{1}$ and $v$ encode the marking $M_{2}$. Then we want $(w,v)$ to be accepted by the transducer, if there is a transition $t$ in the Petri net, where $M_{1}$ becomes $M_{2}$ by firing that transition.

