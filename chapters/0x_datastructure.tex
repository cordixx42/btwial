\chapter{A Data Structure for Weakly Acyclic DFAs}\label{chapter:datastructure}

In order to use weakly acyclic languages efficiently, a data structure for storing the automata efficiently and offering binary set operations is required. This chapter introduces a possible implementation approach for the data structure as well as required operations

\section{Master Automaton}\label{sec:master-aut}
We first look at how multiple weakly acyclic DFAs can be combined/united in theory, by establishing the concept of the master automaton. 
\begin{definition}\label{def:master-aut}
The master automaton over alphabet $\Sigma$ is tuple $M = (Q_{M},\Sigma,\delta_{M},F_{M})$, where 
\begin{itemize}[--,noitemsep]
\item $Q_{M}$ is the set of all weakly acyclic languages over $\Sigma$
\item $\delta_{M}: Q_{M} \times \Sigma \rightarrow Q_{M} \quad \delta_{M}(L,a) = L^{a}$ for every $q \in Q_{M} \ , a \in \Sigma$
\item $L \in F_{M} \ \text{iff} \ \epsilon \in L$
\end{itemize}
\end{definition}
As depicted formally in Definition \autoref{def:master-aut}, the master automaton is a DFA without an initial state but with an infinite number of states, where each state is representing a distinct weakly acyclic language. The transitions $\delta_{M}$ are described using the notion of the residual language with respect to a letter (\autoref{chapter:preliminaries}).

\par

Given a state $L$ of the master automaton, which is characterizing the weakly acyclic language $L$, the language recognized from that state is $L$ \cite[Proposition~8]{blondin_24}. This means, that a DFA for any weakly acyclic language $L$ exists as a finite subautomaton in the master automaton. 
\newline
Formally, that DFA $A_{L}$ is the tuple $(Q_{L},\Sigma,\delta_{L},q_{0L},F_{L})$ where 
\begin{itemize}[--,noitemsep]
\item $Q_{L}$ is the set of states of the master automaton reachable from state $L$
\item $q_{0L}$ is the state $L$
\item $\delta_{L}$ is the projection of $\delta_{M}$ onto $Q_{L}$
\item $F_{L}$ is the intersection of $F_{M}$ and $Q_{L}$
\end{itemize}
Furthermore, for every weakly acyclic language $L$, $A_{L}$ is also the unique minimal DFA for recognizing $L$ \cite[Proposition~9]{blondin_24}. 

\par

We can define the relation $\preceq$ on the set of all weakly acyclic languages $Q_{M}$, where $L_{1} \preceq L_{2}$ if $L_{1} = L_{2}^{w}$ for some word $w$. By the definition of weakly acyclic DFAs $\preceq$ must be a partial order. The minimal elements of the order satisfy $L = L^{a}$ for every $a \in \Sigma$, which are only $\emptyset$ and $\Sigma^{*}$.
%We can imagine the order as an infinite directed acyclic graph, where an edge from $L_{1}$ to $L_{2}$ means $L_{1} \preceq L_{2}$. Then, the only nodes without outgoing edges in this graph are the languages $\emptyset$ and $\Sigma^{*}$. 
%\newline
%This structure allows for recursive property proofs.



\section{Table of Nodes}
Using the idea of the master automaton, we can construct a data structure to store a finite set of weakly acyclic DFAs, which we call the \textit{Table of Nodes}. For the languages $L_{1},L_{2},\dots,L_{N}$, we take their corresponding states in the master automaton and all their reachable successors and put them as nodes into the table. Every node corresponds to a weakly acyclic language and can be mapped to a state in the master automaton.

\par 

As the transitions of the master automaton are defined using residual languages, we can describe each node uniquely by its direct successor nodes for every letter and if it is a final state.

\par

For an alphabet $\Sigma = \{a_{1}, a_{2},\dots,a_{n} \}$ we define a \textit{node} as a tuple $(q,s,b)$, where
\begin{itemize}[--,noitemsep]
\item $q$ is the node identifier 
\item $s = [q_{1},q_{2},\dots,q_{n}]$ is the successor array of $q$, where $q_{i}$ is the identifier for the node of the residual language of $q$ with respect to the letter $a_{i}$
\item $b \in \{0,1\}$ tells if $q$ is an accepting state ($1$) or not ($0$)
\end{itemize}
For instance, the node for the language $\emptyset$ is $(q_{\emptyset},[q_{\emptyset},\dots,q_{\emptyset}],0)$ and the language of the empty word $\epsilon$ is $(q_{\epsilon},[q_{\emptyset},\dots,q_{\emptyset}],1)$.

\par

The Table of Nodes stores a collection of these nodes and contains a bidirectional mapping between the node identifier and the node's pair of successor array and final flag.
\todo{bidirectional $T[q] = (s,b)$ and $T[(s,b)] = q$}

\par

An example for a table for the alphabet $\Sigma = \{a,b\}$ is given in Table~\ref{tab:tnodes}. The graphical view containing multiple automata for this table is shown next to it in Figure~\ref{fig:tnodes}. Every node uniquely represents a weakly acyclic language, for instance, $q_{4}$ stands for $L(\bm{b^{*}})$, while $q_{3}$ for $L(\bm{ab+ba})$. Therefore, the successor of $q_{3}$ for letter $a$ has to characterize $L(\bm{b})$, which $q_{1}$ does indeed.

\begin{figure}[htb]
\begin{floatrow}
\capbtabbox{%
  \begin{tabular}[t]{ccc}
\toprule
node id & successor array $s$ & final flag $b$ \\
\midrule
$q_{\emptyset}$&$[q_{\emptyset}, q_{\emptyset}]$&$0$\\
$q_{\epsilon}$&$[q_{\emptyset}, q_{\emptyset}]$&$1$\\
$q_{1}$&$[q_{\emptyset}, q_{\epsilon}]$&$0$\\
$q_{2}$&$[q_{\epsilon}, q_{\epsilon}]$&$0$\\
$q_{3}$&$[q_{1}, q_{2}]$&$0$\\
$q_{4}$&$[q_{\emptyset}, q_{4}]$&$1$\\
$q_{5}$&$[q_{\emptyset}, q_{3}]$&$0$\\
\bottomrule
\end{tabular}
}{%
  \caption{Example for a Table of Nodes}%
    \label{tab:tnodes}
}
\ffigbox{%
 \begin{tikzpicture}[node distance=1.3cm,auto]
    	\node[state] (q5) {$q_5$};
    	\node[state, below right=of q5] (q3) {$q_3$};
    	\node[state, below right=of q3] (q2) {$q_2$};
    	\node[state, below left=of q3] (q1) {$q_1$};
    	\node[state, accepting, below right=of q1] (qx) {$q_{\epsilon}$};
    	\node[state, below = 2cm of qx] (qy) {$q_{\emptyset}$};
    	\node[state, accepting, above right=of qy] (q4) {$q_4$};
    	\draw   (q5) edge[above] node{b} (q3);
    	\draw   (q3) edge[above] node{a} (q1);
    	\draw   (q3) edge[above] node{b} (q2);
    	\draw   (q1) edge[above] node{b} (qx);
    	\draw   (q2) edge[above] node{a} (qx);  
    	\draw 	(q4) edge[loop above] node{b} (q4); 
    	\draw 	(q4) edge[above] node{a} (qy);
    	\draw 	(qx) edge node{a,b} (qy);
    	\draw 	(qy) edge[loop left] node{a,b} (qy);
    	\draw 	(q1) edge[below] node{a} (qy);
    	\draw 	(q2) edge[below] node{b} (qy);
    	\draw 	(q5) edge[bend right,below] node{a} (qy);
\end{tikzpicture}
}{
  \caption{Graphical Representation}%
  \label{fig:tnodes}
}
\end{floatrow}
\end{figure}   	
    	
We define the operations $\Succ$, $\allSucc$ and $\final$ to access node elements by the node identifier.
Given a node identifier $q$ and a letter $a_{i} \in \Sigma$, $\Succ(q,a_{i})$ returns the successor element for letter $a_{i}$ in the successor array $s$ of the node matching with $q$. $\allSucc(q)$ returns the whole successor array $s$ of the node. The flag $b$ of the node identified by $q$ is returned by $\final(q)$.
\todo{$q_{\emptyset}$ , $q_{\Sigma^{*}}$ and $q_{\epsilon}$ already exist when creating an empty table}

\par 

The following sections are dedicated to introduce methods, which are defined on the Table Of Nodes. 
\todo{here make clear, that this are class methods ? }

\section{Creation of Nodes into the Table}
This section introduces operations on the table with the purpose to add new nodes. $\make$ is responsible for the creation of new nodes and is the only operation, which can directly change the nodes in the table. $\create$ uses $\make$ to create nodes for a certain restricted language given as input.

\subsection{make}
Naturally, the data structure needs an operation for adding new nodes. We define a procedure $\make$, which takes a successor array $s$ and a flag $b$ as input. An intuitive procedure is presented in \autoref{alg:make1}. 

\par

The operation is defined on an existing Table of Nodes $T$.
The require statement expresses the precondition, that all nodes in $s$ must already exist in the table. In the first two lines, we check if a node with the same successors and final value already exists. If there is this node already in $T$, we return its identifier. If it does not exist, we create a new id for the new node in line 4 and add it into the table $T$. Note, that in addition to the mapping from id to node in line 5, the reverse direction also needs to be inserted into the table in line 6. The new identifier is finally returned.

\begin{algorithm}
\caption{Intuitive $\make$}\label{alg:make1}
\begin{algorithmic}[1]
\Input {$s = [q_{1},\dots,q_{n}], b \in \{0,1\}$}
\Require {$\forall q_{i} \in s: q_{i} \in T$}
%\If{$\exists q \in T: \allSucc(q) = s \land \final(q) = b$}
\If{$\exists q = T[(s,b)]$}
\Return $q$
\Else
\State $q_{\text{new}} \gets \textsf{newId()}$
\State $T[q_{\text{new}}] \gets (s,b)$
\State $T[(s,b)] \gets q_{\text{new}}$
\Return $q_{\text{new}}$
\EndIf
\end{algorithmic}
\end{algorithm}

However, this straight-forward algorithm for $\make$ is not completely correct. If we imagine adding a new node with self-loops for every letter, the identifier of this new node is unknown at this point in time. Therefore, we are not able to construct the successor array $s$ correctly. In order to address this issue, we introduce a special identifier $\self$, which indicates, that the successor is the current node itself. This special id is only used for the creation of a new node in $\make$ and will not appear in later operations with the node. 
For creating the node for $\emptyset$, we then give $\make$ the arguments $s = [\self,\dots,\self]$ and $b = 0$.

\par

Using this treatment for self-loops, we can derive a more complicated but correct version of $\make$. The major problem with the introduction of $\self$ is its interchangeability with the node identifier. Imagine the table already contains the a node $q_{1}$ with $s=[q_{1},q_{1},q_{2},q_{3}]$. If we create a node with $s=[\self,\self,q_{2},q_{3}]$ and the same $b$ as $q_{1}$, the existing $q_{1}$ represents this node already and should be returned. But also for $s=[q_{1},\self,q_{2},q_{3}]$, $s=[\self,q_{1},q_{2},q_{3}]$ and $s=[q_{1},q_{1},q_{2},q_{3}]$ the same holds. In fact, all possible combinations between the node id and $\self$ depict the same successor array. In order for the lookup for existing nodes to work correctly, we thus have to add all of these combinations during the creation of $q_{1}$.

\par 

This is the main change in the next $\make$ procedure in \autoref{alg:makev1}. The first part with the lookup for an existing node stays the same as in \autoref{alg:make1}. But if the node does not exist yet, we add all possible combinations, denoted by $\pi(s)$, in lines 5 and 6. For the mapping from id to $s$ and $b$, the successor array without $\self$s is used. This is performed by line 7, where $s_{[\self / q_{\text{new}}]}$ denotes the array $s$, with the only difference, that each $\self$ is substituted by $q_{\text{new}}$. 
\par
\begin{algorithm}[htb]
\centering
\caption{$\make$ Variant 1}\label{alg:makev1}
\begin{algorithmic}[1]
\Input {$s,b$}
%\Input {$s = [q_{1},\dots,q_{n}], b \in \{0,1\}$}
%\Require {$\forall q_{i} \in s: q_{i} \in T$}
\If{$\exists q = T[(s,b)]$}
\Return $q$
\Else
\State $q_{\text{new}} \gets \textsf{newId()}$
\ForEach{$s' \in \pi(s)$}
\State $T[(s',b)] \gets q_{new}$
\EndFor
\State $s \gets s_{[\self / q_{\text{new}}]}$
%\ForEach{$q_{i} \in s$}
%\If{$q_{i} = \self$}
%\State $q_{i} \gets q_{\text{new}}$
%\EndIf
%\EndFor
\State $T[q_{\text{new}}] \gets s$
\Return $q_{\text{new}}$
\EndIf
\end{algorithmic}
\end{algorithm}
This adapted procedure is much more expensive than the simple one before. Given a successor array with $n$ self-loops, there are $\sum_{k=0}^{n} \binom{n}{k} = 2^{n}$ many ways of combining $\self$ and the actual node id. Thus, the number of permutations are exponential in the number of $\self$s in the successor array. By inserting all of them, not only the time efficiency of $\make$ suffers, but also the table might grow very large.
\par
To avoid some of these issues, another approach for $\make$ is portrayed in \autoref{alg:makev2}. First, a distinction is made between the existence of $\self$ in the successor array $s$. If there is none, we can just perform the simple $\make$ from \autoref{alg:make1}.
The insight is, that besides the two cases, where the successor array only contains either $\self$ or the actual identifier and no combination of both, in all other cases, the only possible nodes to consider for equality are the non-$\self$ identifiers in the array. Therefore, when adding a new node, the table only needs to store those two cases for the lookup. This happens in line 9 with the only $\self$ case, and then in line 11 with the only actual id case, after we replaced every $\self$ with the correct new id.
If nothing has been found in the lookup, the for loop from line 4 to 7 iterates over all non-$\self$ ids $q_{i}$ present in $s$ and inspects if they are identical to the current successors. This happens, by replacing all $\self$ ids with $q_{i}$ into the variable $s_{i}$ and examining the equivalence of $(s_{i},b)$ and the successors and final flag of $q_{i}$ in line 5 and 6.
\par 
\autoref{alg:makev2} does not have a very fast lookup compared to \autoref{alg:makev1}, as all the . Especially in cases, where there are only very few $\self$s and lot of other identifiers, this approach becomes more inefficient. However, the exponential number of permutations in \autoref{alg:makev1} is replaced here with a procedure linear in the length of the successor array $s$.
\par 
In our implementation, a variation of \autoref{alg:makev1} has been implemented. Because the alphabet very small containing 3 letters, and the restriction, that only maximum of one $\self$ exists in a successor array. Therefore, only two insertions into table, one with the $\self$ and one without.

%\begin{minipage}{0.46\textwidth}
%\begin{algorithm}
%\centering
%\caption{$\make$ Variant 1}\label{alg:makev1}
%\begin{algorithmic}[1]
%\Input {$s,b$}
%%\Input {$s = [q_{1},\dots,q_{n}], b \in \{0,1\}$}
%%\Require {$\forall q_{i} \in s: q_{i} \in T$}
%\If{$\exists q = T[(s,b)]$}
%\Return $q$
%\Else
%\State $q_{\text{new}} \gets \textsf{newId()}$
%\ForEach{$s' \in \pi(s)$}
%\State $T[(s',b)] \gets q_{new}$
%\EndFor
%\ForEach{$q_{i} \in s$}
%\If{$q_{i} = \self$}
%\State $q_{i} \gets q_{\text{new}}$
%\EndIf
%\EndFor
%\State $T[q_{\text{new}}] \gets s$
%\Return $q_{\text{new}}$
%\EndIf
%\end{algorithmic}
%\end{algorithm}
%%\end{minipage}
%\hfill
%\begin{minipage}{0.46\textwidth}
\begin{algorithm}[htb]
\caption{$\make$ Variant 2}\label{alg:makev2}
\begin{algorithmic}[1]
\Input {$s,b$}
%\Input {$s = [q_{1},\dots,q_{n}], b \in \{0,1\}$}
%\Require {$\forall q_{i} \in s: q_{i} \in T$}
\If{$\exists \self \in s$}
\If{$\exists q = T[(s,b)]$}
\Return $q$
\EndIf
\ForEach{$q_{i} \in s: q_{i} \neq \self$}
\State $s_{i} \gets s_{[\self / q_{i}]}$
%\State $s_{i} \gets \text{$s$ with every $\self$ replaced with $q_{i}$}$
\If{$T[q_{i}] = (s_{i},b)$}
\Return $q_{i}$
\EndIf
\EndFor
\State $q_{\text{new}} \gets \textsf{newId()}$
\State $T[(s,b)] \gets q_{\text{new}}$
\State $s \gets s_{[\self / q_{\text{new}}]}$
\State $T[(s,b)] \gets q_{\text{new}}$
\State $T[q_{\text{new}}] \gets (s,b)$
\Return $q_{\text{new}}$
\Else
\State perform intuitive $\make$
\EndIf
\end{algorithmic}
\end{algorithm}
%\end{minipage}

\subsection{create}
The operation $\create$ allows to create nodes for a weakly acyclic language given a string. The string contains the concatenation of letters of $\Sigma$ and the Kleene star $*$. With string \texttt{ab*a} the operation returns the identifier for $L(\bm{ab^{*}b})$.

\todo{$a*a$ some cases not handled}


\section{Recursive Algorithms on the Table}
The acyclic structure from the partial order $\preceq$ from \autoref{sec:master-aut} with minimal elements $\emptyset$ and $\Sigma^{*}$ allows us to define operations on the table recursively with $q_{\emptyset}$ and $q_{\Sigma^{*}}$ as the recursion base cases.
\par
An example for such a recursive algorithm is given with the $\union$ operation in \autoref{alg:union}. The input $q_{1}$ and $q_{2}$ are two existing nodes in the table and the output is the node of their union, which is added into the table during the procedure. A $\cache$ stores already computed union results.
\begin{algorithm}[htb]
\caption{Union of Two Nodes}\label{alg:union}
\begin{algorithmic}[1]
\Procedure{union}{$q_{1},q_{2}$}
\If{$\cache[\{q_{1},q_{2}\}]$}
	\Return $\cache[\{q_{1},q_{2}\}]$
\ElsIf{$q_{1} = q_{\Sigma^{*}}$ or $q_{2} = q_{\Sigma^{*}} $}
	\Return $q_{\Sigma^{*}}$
\ElsIf{$q_{1} = q_{\emptyset}$}
	\Return $q_{2}$
\ElsIf{$q_{2} = q_{\emptyset}$}
	\Return $q_{1}$
\EndIf
\State $b \gets (\final(q_{1}) \lor \final(q_{2}))$
\State $\cache[\{q_{1},q_{2}\}] \gets \text{SELF}$
\State $s \gets [q_{\emptyset},\dots,q_{\emptyset}]$
\ForEach {$a_{i} \in \Sigma$}
\State $s[i] \gets \Call{union}{\Succ(q_{1},a_{i}),\Succ(q_{2},a_{i})}$
\EndFor
\State $q_{\text{union}} \gets T.\make(s,b)$
\State $\cache[\{q_{1},q_{2}\}] \gets q_{\text{union}}$
\Return $q_{\text{union}}$
\EndProcedure
\end{algorithmic}
\end{algorithm}
In the first two lines, a lookup in the cache is performed. If there is nothing found in the cache, the boundary cases with the minimal elements are examined. The union of a node with $\Sigma^{*}$ is always $\Sigma^{*}$, which is handled in line 4 and 5. Lines $6-9$ address the cases with $q_{\emptyset}$, where the union of a node with $\emptyset$ is the node itself. 
If this is also not the case, we are constructing the successor array and final flag for this node to pass it to $\make$. 

\par 

The calculation of $b$ is shown in line 10. If either one of $q_{1}$ and $q_{2}$ is an accepting node, then their union is accepting too. For the derivation of the successor nodes, the residual of the union of $q_{1}$ and $q_{2}$ with respect to a letter is required. We use the equality $(L_{1} \cup L_{2})^{a} = L_{1}^{a} \cup L_{2}^{a}$. For every letter $a_{i}$ in $\Sigma$, we recursively perform $\union$ with the successor nodes of both $q_{1}$ and $q_{2}$ for $a_{i}$ in line 14.

\par 

After the construction of $s$ and $b$, we give them to $\make$ and write $q_{\text{union}}$, the id given back by $\make$, into the cache in line 15, before returning it.

\par

Similar to the $\make$ procedure, the possibility of self-loops remain a small obstacle for $\union$. If there is a letter $a$, where both $q_{1} = \Succ(q_{1},a)$ and $q_{2} = \Succ(q_{2},a)$, the successor array of the union also has a self-loop for letter $a$. Consequently, the special id $\self$ has to be written into the position of letter $a$ in $s$. We can achieve this quite elegantly, by writing $\self$ into the cache for $\{q_{1},q_{2}\}$ in line 11 before the computation of $s$. If $\union(q_{1},q_{2})$ is called in line 14, line 2 will return the $\self$ identifier, which has been written into the cache line 11 on the last recursion level. We only need to overwrite the $\self$ in the cache with the correct identifier afterwards in line 16.
\par
Other recursive methods on the table, like $\inter$ for the computation of the intersection of two nodes, have a very similar structure. There is always a cache, which stores already calculated results. The boundary cases in the beginning involve $q_{\emptyset}$ and $q_{\Sigma^{*}}$, the nodes in the successor array are iterated over, and a recursive call is made for each successor node. 

%\section{Transducer}
%We also implement a data structure for representing a transducer over $\Sigma \times \Sigma$, which defines a relation between two languages. A transducer consists of a set of transitions. We specify a transition by the tuple $(p,(a_{x},a_{y}),[p_{1},\dots,p_{m}])$, where $p_{1}$ until $p_{m}$ are the states, which are reached by state $p$ with the letter pair $(a_{x},a_{y})$.
%\par 
%Two sets storing the initial states, and the end states of the transducer.

\section{Pre Algorithm}

\subsection{The Pre Language}\label{sec:pre_theory}
Recall, that a transducer $\mathcal{T}$ is an NFA over $\Sigma \times \Sigma$ and defines a mapping from one regular language to another one.
\begin{definition}\label{def:pre}
$\text{Pre}_{\mathcal{T}}(A) = \{ w \in \Sigma^{*}: (w,v) \in L(\mathcal{T}), v \in L(A) \}$
is the Pre language of a transducer $\mathcal{T} = (Q_{\mathcal{T}},\Sigma,q_{0\mathcal{T}},\delta_{\mathcal{T}},F_{\mathcal{T}})$ with respect to a DFA $A = (Q_{A},\Sigma,q_{0A}, \delta_{A}, F_{A})$. 
\end{definition}

A word $w$ is in the language, if the transducer maps $w$ to a word $v$, which is also accepted by automaton $A$.
Therefore, $\text{Pre}_{\mathcal{T}}(A)$ is the pre-image of transducer $\mathcal{T}$ corresponding to the image $L(A)$. 

\par

A concrete example is depicted in \autoref{fig:pre} with a transducer on the top left and a DFA on the right. The language of $A$ in this case is $L(\bm{(a+b)^{*}c})$. The transducer $\mathcal{T}$ in \autoref{fig:pre-transducer} is a mapping from the language $L(\bm{b^{*}a})$ to $L(\bm{a^{*}c})$. 
Since here the complete image of the transducer $L(\bm{a^{*}c})$ is contained in $L(A)$, $\text{Pre}_{\mathcal{T}}(A)$ is the language $L(\bm{b^{*}a})$. 
\todo{here for dfa trap state left out}
\begin{figure}[htb]
\centering 
	\begin{subfigure}{.45\textwidth}	
		\centering 
        \begin{tikzpicture}
    	\node[state, initial] (q1) {$q_1$};
    	\node[state, accepting, right of=q1] (q2) {$q_2$};
    	\draw   (q1) edge[loop above] node{(b,a)} (q1)
            	(q1) edge[above] node{(a,c)} (q2);
    	\end{tikzpicture}
    	\caption{Transducer $\mathcal{T}$}\label{fig:pre-transducer}
    \end{subfigure}
    \begin{subfigure}{.45\textwidth}
	\centering 
		\begin{tikzpicture}
    	\node[state, initial] (q1) {$q_3$};
    	\node[state, accepting, right of=q1] (q2) {$q_4$};
    	\draw   (q1) edge[loop above] node{a,b} (q1)
            	(q1) edge[ above] node{c} (q2);
    	\end{tikzpicture}
    	\caption{DFA $A$}\label{fig:pre-dfa}
    \end{subfigure}
     \caption{Example of Pre Language}
     \label{fig:pre}
\end{figure}

\begin{lemma}\label{prop:b}
The language $\text{Pre}_{\mathcal{T}}(A)$ can be described by the NFA $B = (Q_{B},\Sigma,q_{0B},\delta_{B},F_{B})$, where 
\begin{itemize}[--,noitemsep]
\item $Q_{B} = Q_{\mathcal{T}} \times Q_{A}$
\item $q_{0B} = (q_{0\mathcal{T}},q_{0A})$
\item $F_{B} = F_{\mathcal{T}} \times F_{A}$
\item $\delta_{B}((p,q),x) = \{(p',q'): \exists y \in \Sigma \text{ such that } p' \in \delta_{\mathcal{T}}(q,(x,y)), q' = \delta_{A}(q,y)\}$
\end{itemize}
\end{lemma}

Lemma~\autoref{prop:b} defines a construction of an NFA $B$, which accepts the Pre language from Definition~\autoref{def:pre}. 
The structure of $B$ shows similarities with the product construction for the intersection of two DFAs. In fact, $B$ can be viewed precisely as the NFA for the pre-image of the intersection of a DFA with the image of a transducer. Each state in $B$ is a pair of a state in $\mathcal{T}$ and a state in $A$. The initial state $q_{0B}$ is the pair of initial states of $\mathcal{T}$ and $A$, like depicted in \autoref{fig:pre}. The final states are the pairs of final states of both $\mathcal{T}$ and $A$.
 
\par

The transition function $\delta_{B}$ takes a state $(p,q)$, where $p$ is a state of the transducer and $q$ a state of the DFA, and a letter $x$. The set of states given back are all $(p',q')$, where there is a letter $y$ with the following conditions:

\begin{itemize}[--,noitemsep]
\item in transitions of $\mathcal{T}$ there exists the transition $p \xrightarrow{(x,y)} p'$
\item in transitions of $A$ there exists the transition $q \xrightarrow{y} q'$
\end{itemize}

Taking \autoref{fig:pre} as an example, there exists a transition from $(p,q)=(q_{1},q_{3})$ to $(p',q')=(q_{2},q_{4})$ with letter $x=a$ in $B$, because there is $y=c$ such that:

\begin{itemize}[--,noitemsep]
\item in transitions of $\mathcal{T}$ there exists the transition $q_{1} \xrightarrow{(a,c)} q_{2}$ (\autoref{fig:pre-transducer})
\item in transitions of $A$ there exists the transition $q_{3} \xrightarrow{c} q_{4}$ (\autoref{fig:pre-dfa})
\end{itemize}
Using this construction, the resulting NFA $B$ for the example in \autoref{fig:pre} is depicted in \autoref{fig:pre-result} and characterizes the language $L(\bm{b^{*}a})$ as expected.

\begin{figure}[htb]
		\begin{tikzpicture}
    	\node[state, initial] (q1) {$(q_1,q_3)$};
    	\node[state, accepting, right of=q1] (q2) {$(q_2,q_4)$};
    	\draw   (q1) edge[loop above] node{b} (q1)
            	(q1) edge[above] node{a} (q2);
    	\end{tikzpicture}
    	\caption{$\text{Pre}_{\mathcal{T}}(A)$ for \autoref{fig:pre}}\label{fig:pre-result}
\end{figure}

As we operate with weakly acyclic languages on the Table Of Nodes, an important question arises, if weakly acyclic languages are also closed under the pre-image. Specifically, given a weakly acyclic $A$ and weakly acyclic $\mathcal{T}$, we wonder if $\text{Pre}_{\mathcal{T}}(A)$ also remains weakly acyclic. Note here, that we call a transducer weakly acyclic, if the underlying NFA is weakly acyclic. Blondin et al. have shown, that this is not the case in general. They introduce an additional syntactically defined property for transducers, which guarantees the weakly acyclicity for the result of $\text{Pre}_{\mathcal{T}}(A)$\cite{blondin_24}.

\subsection{Pre Operation On The Table}
We aim to incorporate the calculation of the Pre language into the Table Of Nodes with the operation $\pre$. For a transducer $\mathcal{T}$ and a node with id $q$, $\pre$ returns the node for the language $\text{Pre}_{\mathcal{T}}(q)$, which either was already present in the table, or has been added during the operation.

\par

We already encounter two impediments with the integration into the table. The first one, already mentioned in the last chapter, is about the result of the $\pre$ operation not always being weakly acyclic. This is a substantial problem, as the table has been created for storing weakly acyclic languages, and the operations on the table take advantage of the properties of this specific class of languages.
The second problem is, that the result automaton $B$ in Lemma~\ref{prop:b} is an NFA and might be non-deterministic. The table only stores weakly acyclic DFAs, so another step of determinizing $B$ is required.

%Even though weakly acyclic languages are not closed under the pre-image in general, we construct an algorithm $\pre$, which returns the correct node for $\text{Pre}_{\mathcal{T}}(A)$, if the result is weakly acyclic. If the result is not weakly acyclic, an error identifier is given back. 

\par

For the first impediment, we are not introducing any restrictions on the transducer to ensure, that the resulting language is weakly acyclic. We guarantee a correct result of the operation if the result is weakly acyclic. However, if this is not fulfilled, the algorithm is behaving undefined. 

\par

To address the issue of non-determinism, we use the idea behind the powerset construction, where the states of the DFA represent a set of states from the NFA. By operating with sets of 
states from the NFA $B$ throughout the whole algorithm, we immediately generate the corresponding determinized DFA states.
Therefore, the first argument $S$ of $\pre$ represents a state in the determinized DFA of the Pre language and is composed of states from $B$.  
\todo{we want to construct the correct node into the table for $S$}
Each state in $B$ is a pair containing a state of the transducer ($Q_{\mathcal{T}}$) in the first position and a state of the table ($Q_{T}$) in the second position. The second argument is the transducer.

\par

We first present a more simple but more restrictive algorithm of $\pre$, before adding some measures to achieve the final algorithm.

\par 

%The idea is to not add a separate determinization step at the end, which would convert the NFA into a DFA, but calculate the DFA states directly. We use the idea behind the powerset construction, where the states of the DFA represent a set of states from the NFA. By operating with sets of NFA states throughout the whole algorithm, we immediately generate the DFA states.

The procedure is sketched in \autoref{alg:pre} and is parallel to the construction of $B$ in Lemma~\ref{prop:b}. We write $Q_{T}$ for all nodes and $F_{T}$ for all accepting nodes in the table $T$. Analogous to the last section, the transducer $\mathcal{T} = (Q_{\mathcal{T}},\Sigma,q_{0\mathcal{T}},\delta_{\mathcal{T}},F_{\mathcal{T}})$.
\par 
In the beginning of the algorithm we make a lookup in the cache. 
Then in line 4, the current state $S$ is set to be accepting, if there is a pair in $S$, where both states in the pair are final states in their respective domains (transducer and the table). This aligns with $F_{B}$ from Lemma~\ref{prop:b}. 
Hereafter, we calculate the correct successors $s$ for $S$. Like in $\union$, all letters $a_{i}$ in the alphabet are iterated over. $S'$ is representing the set of states of the NFA $B$, which all states $(p,q) \in S$ reach with the transition $\delta_{B}((p,q),a_{i})$. We first reset $S'$ to the empty set in the beginning of each iteration in line 7, before adding the states according to $\delta_{B}$ of Lemma~\ref{prop:b} for every pair $(p,q) \in S$ in line 9. Here, $\Succ(q,a_{i})$ returns the successor language with respect to the letter $a_{i}$, which+ agrees with $\delta_{A}(q,a_{i})$. 
After having finished computing $S'$, it is checked, whether $S'$ is the same as $S$. If this is the case, that successor is $S$ itself and we insert the $\self$ identifier. Else we recursively call $\pre$ with $S'$. 
\todo{Why does recursion end} 
\par

After the calculation of the whole array $s$, $\make$ is called for $(s,b)$. The identifier given back is written into the cache and then returned. 

\begin{algorithm}
\caption{Pre First Version}\label{alg:pre0}
\begin{algorithmic}[1]
\Input {$S \subseteq Q_{\mathcal{T}} \times Q_{T}, \mathcal{T}$}
\Procedure{pre}{$S, \mathcal{T}$}
\If{$\cache[S]$}
\Return $\cache[S]$
\EndIf
%\State $\cache[S] \gets \invalid$
\State $b \gets (S \cap (F_{\mathcal{T}} \times F_{T} ) \neq \emptyset)$
\State $s \gets [q_{\emptyset},\dots,q_{\emptyset}]$
\ForEach {$a_{i} \in \Sigma$}
\State $S' \gets \emptyset$
\ForEach {$(p,q) \in S$}
\State $S' \gets S' \cup \{(p',q'): \exists y \in \Sigma \text{ such that } p' \in \delta_{\mathcal{T}}(q,(a_{i},y)), q' = \Succ(q,a_{i})\}$
%\State $S' \gets S' \cup \{ (p',q'): p' \in \delta_{\mathcal{T}}(p,(a_{i},b)), q'=\Succ(q,a_{i}) \ \text{for some $b \in \Sigma$} \}$
\EndFor
\If{$S = S'$}
\State $s[i] \gets \self$
\Else
\State $s[i] \gets \Call{pre}{S',\mathcal{T}}$
\EndIf
\EndFor
\State $q_{\text{pre}} \gets T.\make(s,b)$
\State $\cache[S] \gets q_{\text{pre}}$
\Return $q_{\text{pre}} $
\EndProcedure
\end{algorithmic}
\end{algorithm}

This algorithm is not functioning for all cases, where the result language is weakly acyclic. Consider the example given in \autoref{fig:pre-counter} with $\Sigma = \{a,b\}$. The NFA $B$ for the Pre language in \autoref{fig:pre-b} is portraying the language $L(\bm{(a+b)^{*}})$, which is weakly acyclic since its minimal automaton is only one state with self loop for $a$ and $b$. However, after determinizing $B$ the result automaton in \autoref{fig:pre-det-b} is not weakly acyclic. 
%This means for our \autoref{alg:pre0}, that it will fall into an infinity loop. 
\par
We can imagine this example as input for the \autoref{alg:pre0}.
In detail, the algorithm starts with input $S=\{(q_{1},q_{3})\}$, which is the initial node in \autoref{fig:pre-det-b}. In the first iteration of the loop for letter $a$ starting from line 6, the set $S'$ is the same as $S$, as can be also seen in in \autoref{fig:pre-det-b} with the self loop in state  $(q_{1},q_{3})$. Therefore, the condition in line 10 evaluates to true and no recursive call is made in this iteration. In the second one with letter $b$, $\pre$ is called with $S'= \{(q_{1},q_{3}),(q_{2},q_{3})\}$ in line 13. Now we are one recursion level down and the current $S=\{(q_{1},q_{3}),(q_{2},q_{3})\}$. Again, we iterate over the loop starting with letter $a$ and compute $S'=\{(q_{1},q_{3})\}$. At this point, $\pre$ with argument $S'=\{(q_{1},q_{3})\}$ is called in line 13, which is exactly the same configuration we started from. Therefore, for this example \autoref{alg:pre0} will run into an infinite loop without terminating, even though the result is a weakly acyclic language.


\begin{figure}[htb]
\centering 
	\begin{subfigure}{.45\textwidth}	
		\centering 
        \begin{tikzpicture}
    	\node[state, initial] (q1) {$q_1$};
    	\node[state, accepting, right of=q1] (q2) {$q_2$};
    	\draw   (q1) edge[loop above] node{(a,a),(b,b)} (q1)
            	(q1) edge[above] node{(b,a)} (q2);
    	\end{tikzpicture}
    	\caption{Transducer $\mathcal{T}$}\label{fig:pre-transducer-counter}
    \end{subfigure}
    \begin{subfigure}{.46\textwidth}
	\centering 
		\begin{tikzpicture}
    	\node[state, accepting, initial] (q1) {$q_3$};
    	\draw   (q1) edge[loop above] node{a,b} (q1)
    	\end{tikzpicture}
    	\caption{DFA $A$}\label{fig:pre-dfa}
    \end{subfigure}
    \begin{subfigure}{.45\textwidth}	
		\centering 
        \begin{tikzpicture}
    	\node[state, accepting, initial] (q1) {$(q_1,q_3)$};
    	\node[state, accepting, right of=q1] (q2) {$(q_2,q_3)$};
    	\draw   (q1) edge[loop above] node{a,b} (q1)
            	(q1) edge[above] node{b} (q2);
    	\end{tikzpicture}
    	\caption{NFA $B$ for $\text{Pre}_{\mathcal{T}}(A)$}\label{fig:pre-b}
    \end{subfigure}
    \begin{subfigure}{.46\textwidth}
	\centering 
		\begin{tikzpicture}
    	\node[state, initial, accepting] (q1) {$(q_1,q_3)$};
    	\node[state, accepting, right of=q1, font=\fontsize{8}{0}\selectfont] (q2){$(q_1,q_3),(q_2,q_3)$};
    	\draw   (q1) edge[loop above] node{a} (q1)
    			(q1) edge[bend left,above] node{b} (q2)
    			(q2) edge[loop above] node{b} (q2)
    			(q2) edge[bend left, above] node{a} (q1);
    	\end{tikzpicture}
    	\caption{Determinized $B$}\label{fig:pre-det-b}
    \end{subfigure}
     \caption{Counter Example for \autoref{alg:bw}}
     \label{fig:pre-counter}
\end{figure}



\begin{algorithm}
\caption{Pre}\label{alg:pre}
\begin{algorithmic}[1]
\Require { $L \subseteq Q_{\mathcal{T}} \times  Q_{T}$} 
\Procedure{pre}{$S \subseteq Q_{\mathcal{T}} \times Q_{T}, \mathcal{T}$}
\If{$\cache[S]$}
\Return $\cache[S]$
\EndIf
\State \hl{$\cache[S] \gets \invalid$}
\State $b \gets (S \cap (F_{\mathcal{T}} \times F_{T} ) \neq \emptyset)$
\State $s \gets [q_{\emptyset},\dots,q_{\emptyset}]$
\ForEach {$a_{i} \in \Sigma$}
\State $S' \gets \emptyset$
\ForEach {$(p,q) \in S$}
\State $S' \gets S' \cup \{ (p',q'): p' \in \delta_{\mathcal{T}}(p,(a_{i},b)), q'=\Succ(q,a_{i}) \ \text{for some $b \in \Sigma$} \}$
\EndFor
\If{$S = S'$}
\State $s[i] \gets \self$
\ElsIf {$\exists q = \invalid = \cache[S']$}
\State $L \gets S'$
\Return $\abort$
\Else
\State $s[i] \gets \Call{pre}{S',\mathcal{T}}$
\If{$s[i] = \abort$}
\If{$L = S$}
\State $L \gets \emptyset$
\State $s[i] \gets \self$
\Else
\Return $\abort$
\EndIf 
\EndIf
\EndIf
\EndFor
\State $q_{\text{pre}} \gets T.\make(s,b)$
\State $\cache[S] \gets q_{\text{pre}}$
\Return $q_{\text{pre}} $
\EndProcedure
\end{algorithmic}
\end{algorithm}

\subsection{Final Version of Pre}
